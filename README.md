TWO-Bench Benchmarking Script

-This project is a benchmark script designed to compare our own pre-trained small language models on the TWO-Bench dataset.

-The benchmark feeds the model a prefix and evaluates the likelihood of two different continuations (one correct/grammatical, the other inverted or ungrammatical). The model is expected to assign a higher probability to the correct continuation.
